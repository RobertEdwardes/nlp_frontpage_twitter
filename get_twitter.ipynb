{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": [
                "import datetime\r\n",
                "import sqlite3 as sql \r\n",
                "import requests\r\n",
                "import re\r\n",
                "import nltk\r\n",
                "import json\r\n",
                "from nltk.sentiment.vader import SentimentIntensityAnalyzer\r\n",
                "import pandas as pd\r\n",
                "import numpy as np\r\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
                "from config_wip import config\r\n",
                "bearertoken=config['bear_token']\r\n",
                "headers = {'Authorization': 'Bearer ' +\r\n",
                "       bearertoken, 'Content-Type': 'application/json'}"
            ],
            "metadata": {
                "azdata_cell_guid": "351283b6-8b8d-4809-a1fd-d5c1a402260e",
                "language": "python"
            },
            "outputs": [],
            "execution_count": 5
        },
        {
            "cell_type": "code",
            "source": [
                "con = sql.connect(config['database'])\r\n",
                "cur = con.cursor()\r\n",
                "cur.execute('''CREATE TABLE IF NOT EXISTS twitter_tweet_to_user (tweet_id INT, user_id INT)''')\r\n",
                "cur.execute('''CREATE TABLE IF NOT EXISTS twitter_tweet (tweet_id INT, conersation_id INT, text TEXT, likes INT, retweets INT, replay INT, quote INT, created TEXT)''')\r\n",
                "cur.execute('''CREATE TABLE IF NOT EXISTS twitter_nea (tweet_id INT, text TEXT, entity TEXT)''')\r\n",
                "cur.execute('''CREATE TABLE IF NOT EXISTS twitter_tweet_mention (tweet_id INT, mention_id INT, mention_name TEXT)''')\r\n",
                "cur.execute('''CREATE TABLE IF NOT EXISTS twitter_tweet_hash_tags (tweet_id INT, hash_tags TEXT)''')\r\n",
                "cur.execute('''CREATE TABLE IF NOT EXISTS twitter_tweet_urls (tweet_id INT, url TEXT, title TEXT)''')\r\n",
                "cur.execute('''CREATE TABLE IF NOT EXISTS twitter_tweet_conText_entity (tweet_id INT, entity_id INT)''')\r\n",
                "cur.execute('''CREATE TABLE IF NOT EXISTS twitter_tweet_conText_domain (tweet_id INT, domain_id INT)''')\r\n",
                "cur.execute('''CREATE TABLE IF NOT EXISTS twitter_tweet_conText_def (id INT, name TEXT, description TEXT, type TEXT, PRIMARY KEY(id,type)) ''')\r\n",
                "con.commit()"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "52467765-bd00-47a9-92cf-83996eadca32"
            },
            "outputs": [],
            "execution_count": 32
        },
        {
            "cell_type": "code",
            "source": [
                "def twitter_query(kw, headers, cur):\r\n",
                "    date = datetime.datetime.now() - datetime.timedelta(days=1)\r\n",
                "    date = date.strftime(\"%Y-%m-%dT%H:%M:%SZ\") \r\n",
                "    kw = kw.replace(' ', '%20')\r\n",
                "    BASE_URL = f\"https://api.twitter.com/2/tweets/search/recent?query=({kw})%20is%3Averified%20lang%3Aen%20-is%3Aretweet&start_time={date}&tweet.fields=id,author_id,context_annotations,conversation_id,created_at,entities,lang,public_metrics,text\"\r\n",
                "    auth_response_QUERY = requests.get(BASE_URL,  headers=headers)\r\n",
                "    auth_response_RESPONSE = json.loads(auth_response_QUERY.text)\r\n",
                "    if 'errors' in list(auth_response_RESPONSE.keys()):\r\n",
                "        print(auth_response_RESPONSE['errors'])\r\n",
                "        break\r\n",
                "    try:\r\n",
                "        for j in auth_response_RESPONSE['data']:\r\n",
                "            input_dict = {\r\n",
                "            'lang' : None,\r\n",
                "            'hashtags' : [],\r\n",
                "            'url' : [],\r\n",
                "            'title' : [],\r\n",
                "            'tweet_domain' : [],\r\n",
                "            'tweet_entity' : [],\r\n",
                "            'tweet_mentions' : [],\r\n",
                "            'conversation_id' : None,\r\n",
                "            'tweet_id' : j['id'],\r\n",
                "            'text' : j['text'].replace(\"'\",\"''\"),\r\n",
                "            'author_id' : j['author_id'],\r\n",
                "            'created_at' : j['created_at'],\r\n",
                "            'public_metrics': j['public_metrics'],\r\n",
                "            'nea' : []\r\n",
                "            }\r\n",
                "            if 'lang' in list(j.keys()):\r\n",
                "                input_dict['lang'] = j['lang']\r\n",
                "                if input_dict['lang'] != 'en':\r\n",
                "                    continue\r\n",
                "            if 'entities' in list(j.keys()):\r\n",
                "                if 'hashtags' in list(j['entities'].keys()):\r\n",
                "                    for i in j['entities']['hashtags']:\r\n",
                "                        hash_query = f\"INSERT INTO twitter_tweet_hash_tags VALUES ({input_dict['tweet_id']}, '{i['tag']}')\"\r\n",
                "                        cur.execute(hash_query)\r\n",
                "                        con.commit()\r\n",
                "                if 'urls' in list(j['entities'].keys()):\r\n",
                "                    for i in j['entities']['urls']:\r\n",
                "                        if 'unwound_url' in list(i.keys()):\r\n",
                "                            title = i['title'].replace(\"'\",\"''\")\r\n",
                "                            url_query = f\"INSERT INTO twitter_tweet_urls VALUES ({input_dict['tweet_id']}, '{i['unwound_url']}', '{title}')\"\r\n",
                "                            cur.execute(url_query)\r\n",
                "                            con.commit()\r\n",
                "                if 'annotations' in list(j['entities'].keys()):\r\n",
                "                    for i in j['entities']['annotations']:\r\n",
                "                        nea_query = f\"INSERT INTO twitter_nea VALUES ({input_dict['tweet_id']}, '{i['normalized_text']}', '{i['type']}')\"\r\n",
                "                        cur.execute(nea_query)\r\n",
                "                        con.commit()\r\n",
                "                \r\n",
                "                if 'mentions' in list(j['entities'].keys()):\r\n",
                "                    for i in j['entities']['mentions']:\r\n",
                "                        mention_query = f\"INSERT INTO twitter_tweet_mention VALUES ({input_dict['tweet_id']}, {i['id']}, '{i['username']}')\"\r\n",
                "                        cur.execute(mention_query)\r\n",
                "                        con.commit()\r\n",
                "            if 'context_annotations' in list(j.keys()):\r\n",
                "                for i in j['context_annotations']:\r\n",
                "                    d_name = i['domain']['name'].replace(\"'\",\"''\")\r\n",
                "                    d_des = i['domain']['description'].replace(\"'\",\"''\")\r\n",
                "                    conText_d = f\"INSERT INTO twitter_tweet_conText_domain VALUES ({input_dict['tweet_id']}, {i['domain']['id']})\"\r\n",
                "                    conDef_d = f\"INSERT INTO twitter_tweet_conText_def VALUES ({i['domain']['id']}, '{d_name}', '{d_des}', 'domain') ON CONFLICT(id,type) DO NOTHING\"\r\n",
                "                    conText_e = f\"INSERT INTO twitter_tweet_conText_entity VALUES ({input_dict['tweet_id']}, {i['entity']['id']})\"\r\n",
                "                    e_name = i['entity']['name'].replace(\"'\",\"''\")\r\n",
                "                    if 'description' not in  list(i.keys()):\r\n",
                "                        e_des=  None\r\n",
                "                    else:\r\n",
                "                        e_des = i['entity']['description'].replace(\"'\",\"''\")\r\n",
                "                    conDef_e = f\"INSERT INTO twitter_tweet_conText_def VALUES ({i['entity']['id']}, '{e_name}', '{e_des}', 'entity') ON CONFLICT(id,type) DO NOTHING\"\r\n",
                "                    cur.execute(conText_d)\r\n",
                "                    cur.execute(conDef_d)\r\n",
                "                    cur.execute(conText_e)\r\n",
                "                    cur.execute(conDef_e)\r\n",
                "                    con.commit()\r\n",
                "            if 'conversation_id' in list(j.keys()):\r\n",
                "                input_dict['conversation_id'] = j['conversation_id']\r\n",
                "            tweet_query = f\"INSERT INTO twitter_tweet VALUES ({input_dict['tweet_id']},{input_dict['conversation_id']},'{input_dict['text']}', {input_dict['public_metrics']['like_count']}, {input_dict['public_metrics']['retweet_count']}, {input_dict['public_metrics']['reply_count']}, {input_dict['public_metrics']['quote_count']},'{input_dict['created_at']}')\"\r\n",
                "            user_tweet_join_query = f\"INSERT INTO twitter_tweet_to_user VALUES ({input_dict['tweet_id']},{input_dict['author_id']})\"\r\n",
                "            cur.execute(tweet_query)\r\n",
                "            cur.execute(user_tweet_join_query)\r\n",
                "            con.commit()\r\n",
                "    except Exception as e:\r\n",
                "        print(e)\r\n",
                ""
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "ec862332-8969-422c-bbd1-c495070217b3"
            },
            "outputs": [
                {
                    "traceback": [
                        "\u001b[1;36m  Input \u001b[1;32mIn [90]\u001b[1;36m\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
                    ],
                    "ename": "SyntaxError",
                    "evalue": "'break' outside loop (2254065819.py, line 10)",
                    "output_type": "error"
                }
            ],
            "execution_count": 90
        },
        {
            "cell_type": "code",
            "source": [
                "def get_sample(con, n=15, exact=False):\r\n",
                "    sql_query = f\"\"\"SELECT * FROM NEA_Report\r\n",
                "    WHERE label IN ('ORG','PERSON') \r\n",
                "    ORDER BY RANDOM() \r\n",
                "    LIMIT {n};\"\"\"\r\n",
                "    df = pd.read_sql(sql_query,con)\r\n",
                "    if exact:\r\n",
                "        return ['\"'+str(i.replace('\\n', ' '))+'\"' for i in df['nea_text'].to_list()]\r\n",
                "    else:\r\n",
                "        return [i.replace('\\n', ' ') for i in df['nea_text'].to_list()]"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "699f989f-e0d0-4a9d-b8ae-94004239201c"
            },
            "outputs": [],
            "execution_count": 76
        },
        {
            "cell_type": "code",
            "source": [
                "sample = get_sample(con)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "c29c4085-ad7b-4149-a126-e4cda0a1f2a1"
            },
            "outputs": [],
            "execution_count": 81
        },
        {
            "cell_type": "code",
            "source": [
                "kw = ' OR '.join(sample)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "cfdd7019-c780-40ad-b80d-8e663c2eca6b"
            },
            "outputs": [],
            "execution_count": 82
        },
        {
            "cell_type": "code",
            "source": [
                "twitter_query(kw, headers, cur)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "2deebcbc-7893-476a-8141-12ef596d50f5"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "[{'parameters': {' HENRY COLLEGE  Sullivan County  Bomb) is:verified lang:en -is:retweet': ['']}, 'message': 'The query parameter [ HENRY COLLEGE  Sullivan County  Bomb) is:verified lang:en -is:retweet] is not one of [query,start_time,end_time,since_id,until_id,max_results,next_token,pagination_token,sort_order,expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields]'}]\n",
                    "output_type": "stream"
                },
                {
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "Input \u001b[1;32mIn [91]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtwitter_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur\u001b[49m\u001b[43m)\u001b[49m\n",
                        "Input \u001b[1;32mIn [86]\u001b[0m, in \u001b[0;36mtwitter_query\u001b[1;34m(kw, headers, cur)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(auth_response_RESPONSE\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(auth_response_RESPONSE[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[43mauth_response_RESPONSE\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m     11\u001b[0m     input_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhashtags\u001b[39m\u001b[38;5;124m'\u001b[39m : [],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnea\u001b[39m\u001b[38;5;124m'\u001b[39m : []\n\u001b[0;32m     26\u001b[0m     }\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(j\u001b[38;5;241m.\u001b[39mkeys()):\n",
                        "\u001b[1;31mKeyError\u001b[0m: 'data'"
                    ],
                    "ename": "KeyError",
                    "evalue": "'data'",
                    "output_type": "error"
                }
            ],
            "execution_count": 91
        },
        {
            "cell_type": "code",
            "source": [
                "kw"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "9cc0bb54-10a9-4243-8417-b49525f4dab5"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "'Herbert%20Nelson%20OR%20Daily%20Times%20OR%20CentralMaine.com%20OR%20Department’s%20OR%20Johnson%20OR%20the%20Ballad%20Health%20COPA%20OR%20Sioux%20%20Falls%20%20Police%20%20Department%20OR%20STEM%20OR%20THE%20USA%20TODAY%20OR%20Justice%20Department%20OR%20Ma%20OR%20Stockdale%20Highway%20OR%20Cuomo%20OR%20Carrie%20Napoleon%20OR%20EMORY%20&%20HENRY%20COLLEGE%20%20Sullivan%20County%20%20Bomb'"
                    },
                    "metadata": {},
                    "execution_count": 92,
                    "output_type": "execute_result"
                }
            ],
            "execution_count": 92
        },
        {
            "cell_type": "code",
            "source": [
                "date = datetime.datetime.now() - datetime.timedelta(days=1)\r\n",
                "date = date.strftime(\"%Y-%m-%dT%H:%M:%SZ\") \r\n",
                "kw = kw.replace(' ', '%20')\r\n",
                "BASE_URL = f\"https://api.twitter.com/2/tweets/search/recent?query=({kw})%20is%3Averified%20lang%3Aen%20-is%3Aretweet&start_time={date}&tweet.fields=id,author_id,context_annotations,conversation_id,created_at,entities,lang,public_metrics,text\"\r\n",
                "auth_response_QUERY = requests.get(BASE_URL,  headers=headers)\r\n",
                "auth_response_RESPONSE = json.loads(auth_response_QUERY.text)\r\n",
                "if 'errors' in list(auth_response_RESPONSE.keys()):\r\n",
                "    print(kw)\r\n",
                "for j in auth_response_RESPONSE['data']:\r\n",
                "    input_dict = {\r\n",
                "    'lang' : None,\r\n",
                "    'hashtags' : [],\r\n",
                "    'url' : [],\r\n",
                "    'title' : [],\r\n",
                "    'tweet_domain' : [],\r\n",
                "    'tweet_entity' : [],\r\n",
                "    'tweet_mentions' : [],\r\n",
                "    'conversation_id' : None,\r\n",
                "    'tweet_id' : j['id'],\r\n",
                "    'text' : j['text'].replace(\"'\",\"''\"),\r\n",
                "    'author_id' : j['author_id'],\r\n",
                "    'created_at' : j['created_at'],\r\n",
                "    'public_metrics': j['public_metrics'],\r\n",
                "    'nea' : []\r\n",
                "    }\r\n",
                "    if 'lang' in list(j.keys()):\r\n",
                "        input_dict['lang'] = j['lang']\r\n",
                "        if input_dict['lang'] != 'en':\r\n",
                "            continue\r\n",
                "    if 'entities' in list(j.keys()):\r\n",
                "        if 'hashtags' in list(j['entities'].keys()):\r\n",
                "            for i in j['entities']['hashtags']:\r\n",
                "                hash_query = f\"INSERT INTO twitter_tweet_hash_tags VALUES ({input_dict['tweet_id']}, '{i['tag']}')\"\r\n",
                "                cur.execute(hash_query)\r\n",
                "                con.commit()\r\n",
                "        if 'urls' in list(j['entities'].keys()):\r\n",
                "            for i in j['entities']['urls']:\r\n",
                "                if 'unwound_url' in list(i.keys()):\r\n",
                "                    title = i['title'].replace(\"'\",\"''\")\r\n",
                "                    url_query = f\"INSERT INTO twitter_tweet_urls VALUES ({input_dict['tweet_id']}, '{i['unwound_url']}', '{title}')\"\r\n",
                "                    cur.execute(url_query)\r\n",
                "                    con.commit()\r\n",
                "        if 'annotations' in list(j['entities'].keys()):\r\n",
                "            for i in j['entities']['annotations']:\r\n",
                "                nea_query = f\"INSERT INTO twitter_nea VALUES ({input_dict['tweet_id']}, '{i['normalized_text']}', '{i['type']}')\"\r\n",
                "                cur.execute(nea_query)\r\n",
                "                con.commit()\r\n",
                "        \r\n",
                "        if 'mentions' in list(j['entities'].keys()):\r\n",
                "            for i in j['entities']['mentions']:\r\n",
                "                mention_query = f\"INSERT INTO twitter_tweet_mention VALUES ({input_dict['tweet_id']}, {i['id']}, '{i['username']}')\"\r\n",
                "                cur.execute(mention_query)\r\n",
                "                con.commit()\r\n",
                "    if 'context_annotations' in list(j.keys()):\r\n",
                "        for i in j['context_annotations']:\r\n",
                "            d_name = i['domain']['name'].replace(\"'\",\"''\")\r\n",
                "            d_des = i['domain']['description'].replace(\"'\",\"''\")\r\n",
                "            conText_d = f\"INSERT INTO twitter_tweet_conText_domain VALUES ({input_dict['tweet_id']}, {i['domain']['id']})\"\r\n",
                "            conDef_d = f\"INSERT INTO twitter_tweet_conText_def VALUES ({i['domain']['id']}, '{d_name}', '{d_des}', 'domain') ON CONFLICT(id,type) DO NOTHING\"\r\n",
                "            conText_e = f\"INSERT INTO twitter_tweet_conText_entity VALUES ({input_dict['tweet_id']}, {i['entity']['id']})\"\r\n",
                "            e_name = i['entity']['name'].replace(\"'\",\"''\")\r\n",
                "            if 'description' not in  list(i.keys()):\r\n",
                "                e_des=  None\r\n",
                "            else:\r\n",
                "                e_des = i['entity']['description'].replace(\"'\",\"''\")\r\n",
                "            conDef_e = f\"INSERT INTO twitter_tweet_conText_def VALUES ({i['entity']['id']}, '{e_name}', '{e_des}', 'entity') ON CONFLICT(id,type) DO NOTHING\"\r\n",
                "            cur.execute(conText_d)\r\n",
                "            cur.execute(conDef_d)\r\n",
                "            cur.execute(conText_e)\r\n",
                "            cur.execute(conDef_e)\r\n",
                "            con.commit()\r\n",
                "    if 'conversation_id' in list(j.keys()):\r\n",
                "        input_dict['conversation_id'] = j['conversation_id']\r\n",
                "    tweet_query = f\"INSERT INTO twitter_tweet VALUES ({input_dict['tweet_id']},{input_dict['conversation_id']},'{input_dict['text']}', {input_dict['public_metrics']['like_count']}, {input_dict['public_metrics']['retweet_count']}, {input_dict['public_metrics']['reply_count']}, {input_dict['public_metrics']['quote_count']},'{input_dict['created_at']}')\"\r\n",
                "    user_tweet_join_query = f\"INSERT INTO twitter_tweet_to_user VALUES ({input_dict['tweet_id']},{input_dict['author_id']})\"\r\n",
                "    cur.execute(tweet_query)\r\n",
                "    cur.execute(user_tweet_join_query)\r\n",
                "    con.commit()"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "cd31486e-b5a6-4053-b650-e3e434f7c6b4"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Herbert%20Nelson%20OR%20Daily%20Times%20OR%20CentralMaine.com%20OR%20Department’s%20OR%20Johnson%20OR%20the%20Ballad%20Health%20COPA%20OR%20Sioux%20%20Falls%20%20Police%20%20Department%20OR%20STEM%20OR%20THE%20USA%20TODAY%20OR%20Justice%20Department%20OR%20Ma%20OR%20Stockdale%20Highway%20OR%20Cuomo%20OR%20Carrie%20Napoleon%20OR%20EMORY%20&%20HENRY%20COLLEGE%20%20Sullivan%20County%20%20Bomb\n",
                    "output_type": "stream"
                },
                {
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "Input \u001b[1;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(auth_response_RESPONSE\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(kw)\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[43mauth_response_RESPONSE\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m     10\u001b[0m     input_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhashtags\u001b[39m\u001b[38;5;124m'\u001b[39m : [],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnea\u001b[39m\u001b[38;5;124m'\u001b[39m : []\n\u001b[0;32m     25\u001b[0m     }\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(j\u001b[38;5;241m.\u001b[39mkeys()):\n",
                        "\u001b[1;31mKeyError\u001b[0m: 'data'"
                    ],
                    "ename": "KeyError",
                    "evalue": "'data'",
                    "output_type": "error"
                }
            ],
            "execution_count": 88
        },
        {
            "cell_type": "code",
            "source": [
                "list(auth_response_RESPONSE.keys())"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "bfcd8316-23a8-46bf-8919-e74219b90966"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "['errors', 'title', 'detail', 'type']"
                    },
                    "metadata": {},
                    "execution_count": 89,
                    "output_type": "execute_result"
                }
            ],
            "execution_count": 89
        }
    ]
}